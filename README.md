# DataFrameIt

[![PyPI version](https://badge.fury.io/py/dataframeit.svg)](https://badge.fury.io/py/dataframeit)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Enrique√ßa DataFrames com LLMs de forma simples e estruturada.**

DataFrameIt processa textos em DataFrames usando Modelos de Linguagem (LLMs) e extrai informa√ß√µes estruturadas definidas por modelos Pydantic.

**[Documenta√ß√£o Completa](https://bdcdo.github.io/dataframeit)** | **[Refer√™ncia para LLMs](https://bdcdo.github.io/dataframeit/reference/llm-reference/)**

## Instala√ß√£o

```bash
pip install dataframeit  # Groq inclu√≠do (default - free tier permanente!)
pip install dataframeit[google]  # Google Gemini
pip install dataframeit[openai]  # OpenAI
pip install dataframeit[anthropic]  # Anthropic Claude
```

Configure sua API key:

```bash
export GROQ_API_KEY="sua-chave"  # Gratuito em console.groq.com
# Ou: GOOGLE_API_KEY, OPENAI_API_KEY, ANTHROPIC_API_KEY
```

## Exemplo R√°pido

```python
from pydantic import BaseModel
from typing import Literal
import pandas as pd
from dataframeit import dataframeit

# 1. Defina o que extrair
class Sentimento(BaseModel):
    sentimento: Literal['positivo', 'negativo', 'neutro']
    confianca: Literal['alta', 'media', 'baixa']

# 2. Seus dados
df = pd.DataFrame({
    'texto': [
        'Produto excelente! Superou expectativas.',
        'P√©ssimo atendimento, nunca mais compro.',
        'Entrega ok, produto mediano.'
    ]
})

# 3. Processe!
resultado = dataframeit(df, Sentimento, "Analise o sentimento do texto.")
print(resultado)
```

**Sa√≠da:**

| texto | sentimento | confianca |
|-------|------------|-----------|
| Produto excelente! ... | positivo | alta |
| P√©ssimo atendimento... | negativo | alta |
| Entrega ok... | neutro | media |

## üí∞ 100% Gratuito com Groq!

O dataframeit usa **Groq como default**, que oferece **free tier permanente** sem necessidade de cart√£o de cr√©dito:

- ‚úÖ **60 requisi√ß√µes por minuto** (RPM)
- ‚úÖ **10.000 tokens por minuto** (TPM)
- ‚úÖ **Sem limite de tempo** - free tier permanente!
- ‚úÖ **Ultra-r√°pido** - 200+ tokens/segundo

**Cadastre-se gr√°tis:** [console.groq.com](https://console.groq.com)

### Otimizando para o Free Tier

Para evitar rate limits, adicione um pequeno delay entre requisi√ß√µes:

```python
# Recomendado: 1 segundo entre requisi√ß√µes = 60 RPM m√°ximo
resultado = dataframeit(
    df, Sentimento, "Analise o sentimento.",
    rate_limit_delay=1.0  # Delay de 1 segundo entre requisi√ß√µes
)

# Para datasets grandes, use rate_limit_delay + parallel_requests:
resultado = dataframeit(
    df, Sentimento, "Analise o sentimento.",
    rate_limit_delay=1.0,      # 1s entre requisi√ß√µes
    parallel_requests=3,       # 3 requisi√ß√µes simult√¢neas
    track_tokens=True          # Monitore RPM e TPM em tempo real
)
```

**Dica:** O par√¢metro `track_tokens=True` mostra estat√≠sticas em tempo real (RPM, TPM) para voc√™ calibrar os valores ideais.

## Funcionalidades

- **M√∫ltiplos providers**: Groq (default, free tier permanente), Google Gemini, OpenAI, Anthropic, Cohere, Mistral via LangChain
- **M√∫ltiplos tipos de entrada**: DataFrame, Series, list, dict
- **Sa√≠da estruturada**: Valida√ß√£o autom√°tica com Pydantic
- **Resili√™ncia**: Retry autom√°tico com backoff exponencial
- **Performance**: Processamento paralelo, rate limiting configur√°vel
- **Busca web**: Integra√ß√£o com Tavily para enriquecer dados
- **Tracking**: Monitoramento de tokens e m√©tricas de throughput
- **Configura√ß√£o per-field**: Prompts e par√¢metros de busca personalizados por campo (v0.5.2+)

## Configura√ß√£o Per-Field (Novo em v0.5.2)

Configure prompts e par√¢metros de busca espec√≠ficos para cada campo usando `json_schema_extra`:

```python
from pydantic import BaseModel, Field

class MedicamentoInfo(BaseModel):
    # Campo com prompt padr√£o
    principio_ativo: str = Field(description="Princ√≠pio ativo do medicamento")

    # Campo com prompt customizado (substitui o prompt base)
    doenca_rara: str = Field(
        description="Classifica√ß√£o de doen√ßa rara",
        json_schema_extra={
            "prompt": "Busque em Orphanet (orpha.net). Analise: {texto}"
        }
    )

    # Campo com prompt adicional (append ao prompt base)
    avaliacao_conitec: str = Field(
        description="Avalia√ß√£o da CONITEC",
        json_schema_extra={
            "prompt_append": "Busque APENAS no site da CONITEC (gov.br/conitec)."
        }
    )

    # Campo com par√¢metros de busca customizados
    estudos_clinicos: str = Field(
        description="Estudos cl√≠nicos relevantes",
        json_schema_extra={
            "prompt_append": "Busque estudos cl√≠nicos recentes.",
            "search_depth": "advanced",
            "max_results": 10
        }
    )

# Requer search_per_field=True
resultado = dataframeit(
    df,
    MedicamentoInfo,
    "Analise o medicamento: {texto}",
    use_search=True,
    search_per_field=True,
)
```

**Op√ß√µes dispon√≠veis em `json_schema_extra`:**

| Op√ß√£o | Descri√ß√£o |
|-------|-----------|
| `prompt` ou `prompt_replace` | Substitui completamente o prompt base |
| `prompt_append` | Adiciona texto ao prompt base |
| `search_depth` | `"basic"` ou `"advanced"` (override per-field) |
| `max_results` | N√∫mero de resultados de busca (1-20) |

## Documenta√ß√£o

- [In√≠cio R√°pido](https://bdcdo.github.io/dataframeit/getting-started/quickstart/)
- [Guias](https://bdcdo.github.io/dataframeit/guides/basic-usage/)
- [Refer√™ncia da API](https://bdcdo.github.io/dataframeit/reference/api/)
- [Refer√™ncia para LLMs](https://bdcdo.github.io/dataframeit/reference/llm-reference/) - P√°gina compacta otimizada para assistentes de c√≥digo

## Exemplos

Veja a pasta [`example/`](example/) para notebooks Jupyter com casos de uso completos.

## Licen√ßa

MIT
