"""
Exemplo 04: Processamento Incremental com Resume
=================================================

Este exemplo demonstra como usar resume=True para processar datasets grandes
de forma incremental, com capacidade de pausar e continuar.

Conceitos demonstrados:
- Uso de resume=True
- Salvamento de progresso parcial
- Continua√ß√£o ap√≥s interrup√ß√£o
- Monitoramento de progresso
- Estrat√©gias para datasets grandes

Para executar este exemplo:
1. Configure sua chave de API: export GOOGLE_API_KEY="sua-chave"
2. Instale depend√™ncias: pip install dataframeit langchain langchain-core langchain-google-genai openpyxl
3. Execute: python3 example_04_resume.py
"""

from pydantic import BaseModel, Field
from typing import Literal
import pandas as pd
from dataframeit import dataframeit
import os

# ============================================================================
# 1. DEFINIR MODELO PYDANTIC
# ============================================================================
class EmailClassification(BaseModel):
    """Estrutura para classifica√ß√£o de emails."""

    tipo: Literal['trabalho', 'pessoal', 'spam', 'newsletter', 'urgente'] = Field(
        ...,
        description="Tipo/categoria do email"
    )

    prioridade: Literal['alta', 'media', 'baixa'] = Field(
        ...,
        description="Prioridade do email"
    )

    requer_resposta: Literal['sim', 'nao', 'opcional'] = Field(
        ...,
        description="Se o email requer resposta"
    )

# ============================================================================
# 2. DEFINIR TEMPLATE DO PROMPT
# ============================================================================
TEMPLATE = """
Classifique o email abaixo.

Email:
{documento}

Seja preciso na classifica√ß√£o.
"""

# ============================================================================
# 3. CRIAR DATASET SIMULADO (m√©dio porte)
# ============================================================================
# Simulamos 20 emails para demonstrar processamento incremental
emails = [
    "Reuni√£o de planejamento do Q4 amanh√£ √†s 14h. Presen√ßa obrigat√≥ria.",
    "Oi! Vamos jantar no s√°bado?",
    "PROMO√á√ÉO IMPERD√çVEL! 50% de desconto em todos os produtos!",
    "Seu relat√≥rio mensal est√° pronto para revis√£o.",
    "Parab√©ns! Voc√™ ganhou um iPhone! Clique aqui para resgatar.",
    "Newsletter semanal: As principais not√≠cias de tecnologia",
    "URGENTE: Sistema fora do ar - necess√°ria a√ß√£o imediata",
    "Lembrete: Anivers√°rio da Maria √© amanh√£",
    "Proposta comercial anexa para sua an√°lise",
    "Deseja renovar sua assinatura? Desconto especial!",
    "Ata da √∫ltima reuni√£o para aprova√ß√£o",
    "Fotos do fim de semana que voc√™ pediu",
    "Boleto com vencimento hoje - evite multa",
    "Novo epis√≥dio do podcast que voc√™ segue",
    "Preciso da sua aprova√ß√£o urgente no documento",
    "Convite: Churrasco no domingo √†s 15h",
    "Seu pedido #12345 foi enviado",
    "Coment√°rios na sua publica√ß√£o do blog",
    "Atualiza√ß√£o de pol√≠tica de privacidade",
    "Feliz anivers√°rio! Desejo tudo de bom!"
]

dados = {
    'email_id': [f'E{i:03d}' for i in range(1, len(emails) + 1)],
    'texto': emails
}

df_original = pd.DataFrame(dados)

# ============================================================================
# 4. CEN√ÅRIO 1: PROCESSAMENTO COMPLETO COM RESUME
# ============================================================================
print("=" * 80)
print("CEN√ÅRIO 1: PROCESSAMENTO COMPLETO")
print("=" * 80)

print(f"\nüìä Dataset: {len(df_original)} emails para processar")
print("\nIniciando processamento com resume=True...")

# Processar com resume ativado
df_resultado = dataframeit(
    df_original,
    EmailClassification,
    TEMPLATE,
    text_column='texto',
    resume=True,  # CHAVE: Permite continuar de onde parou
    model='gemini-2.0-flash-exp'
)

print("\n‚úì Processamento completo conclu√≠do!")

# Salvar resultado
arquivo_parcial = 'emails_processamento_parcial.xlsx'
df_resultado.to_excel(arquivo_parcial, index=False)
print(f"‚úì Progresso salvo em: {arquivo_parcial}")

# ============================================================================
# 5. AN√ÅLISE DO PROGRESSO
# ============================================================================
print("\n" + "=" * 80)
print("AN√ÅLISE DE PROGRESSO")
print("=" * 80)

status_counts = df_resultado['_dataframeit_status'].value_counts()
total = len(df_resultado)

processados = status_counts.get('processed', 0)
com_erro = status_counts.get('error', 0)
nao_processados = df_resultado['_dataframeit_status'].isna().sum()

print(f"\n  ‚úì Processados: {processados}/{total} ({processados/total*100:.1f}%)")
print(f"  ‚úó Com erro: {com_erro}/{total}")
print(f"  ‚äó N√£o processados: {nao_processados}/{total}")

# ============================================================================
# 6. VISUALIZAR RESULTADOS
# ============================================================================
print("\n" + "=" * 80)
print("RESULTADOS DA CLASSIFICA√á√ÉO")
print("=" * 80)

# Mostrar apenas emails processados
emails_processados = df_resultado[df_resultado['_dataframeit_status'] == 'processed']

if len(emails_processados) > 0:
    print("\nPrimeiros 5 resultados:")
    colunas = ['email_id', 'tipo', 'prioridade', 'requer_resposta']
    print(emails_processados[colunas].head().to_string(index=False))

    print("\n" + "-" * 80)
    print("Estat√≠sticas:")

    print("\nDistribui√ß√£o por tipo:")
    print(emails_processados['tipo'].value_counts())

    print("\nDistribui√ß√£o por prioridade:")
    print(emails_processados['prioridade'].value_counts())

# ============================================================================
# 7. CEN√ÅRIO 2: SIMULANDO INTERRUP√á√ÉO E RETOMADA
# ============================================================================
print("\n" + "=" * 80)
print("CEN√ÅRIO 2: SIMULANDO INTERRUP√á√ÉO E RETOMADA")
print("=" * 80)

print("""
Imagine que o processamento foi interrompido ap√≥s 10 emails.
Vamos simular isso e ent√£o retomar...
""")

# Criar dataset "parcialmente processado"
df_parcial = df_original.copy()

# Simular que apenas os primeiros 10 foram processados
# (adicionando as colunas necess√°rias manualmente)
df_parcial['tipo'] = None
df_parcial['prioridade'] = None
df_parcial['requer_resposta'] = None
df_parcial['_dataframeit_status'] = None
df_parcial['error_details'] = None

# Marcar primeiros 10 como processados (simula√ß√£o)
df_parcial.loc[:9, '_dataframeit_status'] = 'processed'
df_parcial.loc[:9, 'tipo'] = 'trabalho'  # valores dummy
df_parcial.loc[:9, 'prioridade'] = 'media'
df_parcial.loc[:9, 'requer_resposta'] = 'sim'

print(f"‚úì Simula√ß√£o: 10/{len(df_parcial)} emails processados")
print("‚äó Simula√ß√£o: Processamento interrompido!")

# Salvar estado parcial
arquivo_interrompido = 'emails_interrompido.xlsx'
df_parcial.to_excel(arquivo_interrompido, index=False)
print(f"‚úì Estado salvo em: {arquivo_interrompido}")

print("\nüìç Retomando processamento...")

# Carregar e retomar
df_retomado = pd.read_excel(arquivo_interrompido)

# RESUME vai processar apenas as linhas restantes!
df_completo = dataframeit(
    df_retomado,
    EmailClassification,
    TEMPLATE,
    text_column='texto',
    resume=True,  # Continua de onde parou!
    model='gemini-2.0-flash-exp'
)

print("\n‚úì Processamento retomado e conclu√≠do!")

# Salvar resultado final
arquivo_final = 'emails_completo.xlsx'
df_completo.to_excel(arquivo_final, index=False)
print(f"‚úì Resultado final salvo em: {arquivo_final}")

# ============================================================================
# 8. ESTRAT√âGIAS PARA DATASETS GRANDES
# ============================================================================
print("\n" + "=" * 80)
print("ESTRAT√âGIAS PARA DATASETS GRANDES")
print("=" * 80)

print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë 1. PROCESSAMENTO INCREMENTAL COM CHECKPOINTS                          ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë                                                                        ‚ïë
‚ïë # Processar em blocos de 100 linhas                                   ‚ïë
‚ïë for i in range(0, len(df), 100):                                      ‚ïë
‚ïë     bloco = df[i:i+100]                                                ‚ïë
‚ïë     resultado = dataframeit(bloco, Model, TEMPLATE, resume=True)      ‚ïë
‚ïë     resultado.to_excel(f'checkpoint_{i}.xlsx', index=False)           ‚ïë
‚ïë                                                                        ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë 2. MONITORAMENTO DE PROGRESSO                                         ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë                                                                        ‚ïë
‚ïë # Verificar progresso periodicamente                                  ‚ïë
‚ïë df_resultado.to_excel('backup_temp.xlsx', index=False)                ‚ïë
‚ïë                                                                        ‚ïë
‚ïë # Checar quantos faltam                                                ‚ïë
‚ïë faltam = df_resultado['_dataframeit_status'].isna().sum()             ‚ïë
‚ïë print(f"Faltam {faltam} linhas")                                      ‚ïë
‚ïë                                                                        ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë 3. RECUPERA√á√ÉO DE FALHAS                                              ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë                                                                        ‚ïë
‚ïë # Se houver falha, apenas recarregue e continue                       ‚ïë
‚ïë df = pd.read_excel('backup_temp.xlsx')                                ‚ïë
‚ïë df = dataframeit(df, Model, TEMPLATE, resume=True)                    ‚ïë
‚ïë                                                                        ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
""")

# ============================================================================
# 9. BOAS PR√ÅTICAS
# ============================================================================
print("=" * 80)
print("BOAS PR√ÅTICAS PARA PROCESSAMENTO INCREMENTAL")
print("=" * 80)

print("""
‚úì SEMPRE use resume=True para datasets m√©dios/grandes
‚úì Salve progresso periodicamente (.xlsx ou .csv)
‚úì Monitore _dataframeit_status para ver progresso
‚úì Use nomes de arquivo com timestamp para backups
‚úì Processe em blocos para datasets muito grandes (>1000 linhas)
‚úì Tenha uma estrat√©gia de backup antes de come√ßar
‚úì Teste com subset pequeno antes do dataset completo

‚úó N√ÉO processe tudo de uma vez sem checkpoints
‚úó N√ÉO esque√ßa de salvar progresso intermedi√°rio
‚úó N√ÉO use resume=False em datasets grandes
""")

# ============================================================================
# 10. LIMPEZA
# ============================================================================
print("\n" + "=" * 80)
print("LIMPEZA DE ARQUIVOS TEMPOR√ÅRIOS")
print("=" * 80)

arquivos_temp = [arquivo_parcial, arquivo_interrompido, arquivo_final]
for arquivo in arquivos_temp:
    if os.path.exists(arquivo):
        os.remove(arquivo)
        print(f"‚úì Removido: {arquivo}")

print("\n" + "=" * 80)
print("EXEMPLO CONCLU√çDO!")
print("=" * 80)
