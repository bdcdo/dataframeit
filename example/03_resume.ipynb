{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrameIt - Exemplo 04: Processamento Incremental com Resume\n",
    "\n",
    "Este notebook demonstra como usar `resume=True` para processar datasets grandes de forma incremental, com capacidade de pausar e continuar.\n",
    "\n",
    "**Conceitos demonstrados:**\n",
    "- Uso de `resume=True`\n",
    "- Salvamento de progresso parcial\n",
    "- Continua\u00e7\u00e3o ap\u00f3s interrup\u00e7\u00e3o\n",
    "- Monitoramento de progresso\n",
    "- Estrat\u00e9gias para datasets grandes\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bdcdo/dataframeit/blob/main/example/03_resume.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instala\u00e7\u00e3o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q dataframeit[google] openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configura\u00e7\u00e3o da API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
    "    print(\"API Key carregada dos Secrets do Colab\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# os.environ['GOOGLE_API_KEY'] = 'sua-chave-aqui'\n",
    "\n",
    "if 'GOOGLE_API_KEY' not in os.environ:\n",
    "    print(\"AVISO: Configure sua GOOGLE_API_KEY antes de continuar\")\n",
    "else:\n",
    "    print(\"API Key configurada com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "import pandas as pd\n",
    "from dataframeit import dataframeit\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Definir Modelo Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailClassification(BaseModel):\n",
    "    \"\"\"Estrutura para classifica\u00e7\u00e3o de emails.\"\"\"\n",
    "\n",
    "    tipo: Literal['trabalho', 'pessoal', 'spam', 'newsletter', 'urgente'] = Field(\n",
    "        ...,\n",
    "        description=\"Tipo/categoria do email\"\n",
    "    )\n",
    "\n",
    "    prioridade: Literal['alta', 'media', 'baixa'] = Field(\n",
    "        ...,\n",
    "        description=\"Prioridade do email\"\n",
    "    )\n",
    "\n",
    "    requer_resposta: Literal['sim', 'nao', 'opcional'] = Field(\n",
    "        ...,\n",
    "        description=\"Se o email requer resposta\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Definir Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "Classifique o email abaixo.\n",
    "\n",
    "Email:\n",
    "{texto}\n",
    "\n",
    "Seja preciso na classifica\u00e7\u00e3o.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Criar Dataset Simulado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulamos 20 emails para demonstrar processamento incremental\n",
    "emails = [\n",
    "    \"Reuni\u00e3o de planejamento do Q4 amanh\u00e3 \u00e0s 14h. Presen\u00e7a obrigat\u00f3ria.\",\n",
    "    \"Oi! Vamos jantar no s\u00e1bado?\",\n",
    "    \"PROMO\u00c7\u00c3O IMPERD\u00cdVEL! 50% de desconto em todos os produtos!\",\n",
    "    \"Seu relat\u00f3rio mensal est\u00e1 pronto para revis\u00e3o.\",\n",
    "    \"Parab\u00e9ns! Voc\u00ea ganhou um iPhone! Clique aqui para resgatar.\",\n",
    "    \"Newsletter semanal: As principais not\u00edcias de tecnologia\",\n",
    "    \"URGENTE: Sistema fora do ar - necess\u00e1ria a\u00e7\u00e3o imediata\",\n",
    "    \"Lembrete: Anivers\u00e1rio da Maria \u00e9 amanh\u00e3\",\n",
    "    \"Proposta comercial anexa para sua an\u00e1lise\",\n",
    "    \"Deseja renovar sua assinatura? Desconto especial!\",\n",
    "    \"Ata da \u00faltima reuni\u00e3o para aprova\u00e7\u00e3o\",\n",
    "    \"Fotos do fim de semana que voc\u00ea pediu\",\n",
    "    \"Boleto com vencimento hoje - evite multa\",\n",
    "    \"Novo epis\u00f3dio do podcast que voc\u00ea segue\",\n",
    "    \"Preciso da sua aprova\u00e7\u00e3o urgente no documento\",\n",
    "    \"Convite: Churrasco no domingo \u00e0s 15h\",\n",
    "    \"Seu pedido #12345 foi enviado\",\n",
    "    \"Coment\u00e1rios na sua publica\u00e7\u00e3o do blog\",\n",
    "    \"Atualiza\u00e7\u00e3o de pol\u00edtica de privacidade\",\n",
    "    \"Feliz anivers\u00e1rio! Desejo tudo de bom!\"\n",
    "]\n",
    "\n",
    "dados = {\n",
    "    'email_id': [f'E{i:03d}' for i in range(1, len(emails) + 1)],\n",
    "    'texto': emails\n",
    "}\n",
    "\n",
    "df_original = pd.DataFrame(dados)\n",
    "print(f\"Dataset: {len(df_original)} emails para processar\")\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cen\u00e1rio 1: Processamento Completo com Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Iniciando processamento com resume=True...\")\n",
    "\n",
    "# Processar com resume ativado\n",
    "df_resultado = dataframeit(\n",
    "    df_original,\n",
    "    EmailClassification,\n",
    "    TEMPLATE,\n",
    "    text_column='texto',\n",
    "    resume=True  # Permite continuar de onde parou\n",
    ")\n",
    "\n",
    "print(\"Processamento completo conclu\u00eddo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. An\u00e1lise do Progresso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_counts = df_resultado['_dataframeit_status'].value_counts()\n",
    "total = len(df_resultado)\n",
    "\n",
    "processados = status_counts.get('processed', 0)\n",
    "com_erro = status_counts.get('error', 0)\n",
    "nao_processados = df_resultado['_dataframeit_status'].isna().sum()\n",
    "\n",
    "print(f\"Processados: {processados}/{total} ({processados/total*100:.1f}%)\")\n",
    "print(f\"Com erro: {com_erro}/{total}\")\n",
    "print(f\"N\u00e3o processados: {nao_processados}/{total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualizar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_processados = df_resultado[df_resultado['_dataframeit_status'] == 'processed']\n",
    "\n",
    "if len(emails_processados) > 0:\n",
    "    print(\"Primeiros 5 resultados:\")\n",
    "    colunas = ['email_id', 'tipo', 'prioridade', 'requer_resposta']\n",
    "    display(emails_processados[colunas].head())\n",
    "\n",
    "    print(\"\\nDistribui\u00e7\u00e3o por tipo:\")\n",
    "    print(emails_processados['tipo'].value_counts())\n",
    "\n",
    "    print(\"\\nDistribui\u00e7\u00e3o por prioridade:\")\n",
    "    print(emails_processados['prioridade'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Salvar Progresso\n",
    "\n",
    "Salve o progresso para poder continuar depois se necess\u00e1rio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar progresso\n",
    "arquivo_parcial = 'emails_processados.xlsx'\n",
    "df_resultado.to_excel(arquivo_parcial, index=False)\n",
    "print(f\"Progresso salvo em: {arquivo_parcial}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Cen\u00e1rio 2: Retomando Processamento Interrompido\n",
    "\n",
    "Se o processamento for interrompido, voc\u00ea pode continuar de onde parou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simular retomada de processamento\n",
    "print(\"Simulando retomada de processamento...\")\n",
    "\n",
    "# Carregar arquivo salvo\n",
    "df_retomado = pd.read_excel(arquivo_parcial)\n",
    "\n",
    "# Resume vai processar apenas as linhas n\u00e3o processadas!\n",
    "df_completo = dataframeit(\n",
    "    df_retomado,\n",
    "    EmailClassification,\n",
    "    TEMPLATE,\n",
    "    text_column='texto',\n",
    "    resume=True  # Continua de onde parou!\n",
    ")\n",
    "\n",
    "print(\"Processamento retomado e conclu\u00eddo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Estrat\u00e9gias para Datasets Grandes\n",
    "\n",
    "### Processamento em Blocos\n",
    "```python\n",
    "# Processar em blocos de 100 linhas\n",
    "for i in range(0, len(df), 100):\n",
    "    bloco = df[i:i+100]\n",
    "    resultado = dataframeit(bloco, Model, TEMPLATE, resume=True)\n",
    "    resultado.to_excel(f'checkpoint_{i}.xlsx', index=False)\n",
    "```\n",
    "\n",
    "### Monitoramento de Progresso\n",
    "```python\n",
    "# Verificar progresso periodicamente\n",
    "df_resultado.to_excel('backup_temp.xlsx', index=False)\n",
    "\n",
    "# Checar quantos faltam\n",
    "faltam = df_resultado['_dataframeit_status'].isna().sum()\n",
    "print(f\"Faltam {faltam} linhas\")\n",
    "```\n",
    "\n",
    "### Recupera\u00e7\u00e3o de Falhas\n",
    "```python\n",
    "# Se houver falha, apenas recarregue e continue\n",
    "df = pd.read_excel('backup_temp.xlsx')\n",
    "df = dataframeit(df, Model, TEMPLATE, resume=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Boas Pr\u00e1ticas\n",
    "\n",
    "**Recomenda\u00e7\u00f5es:**\n",
    "- SEMPRE use `resume=True` para datasets m\u00e9dios/grandes\n",
    "- Salve progresso periodicamente (.xlsx ou .csv)\n",
    "- Monitore `_dataframeit_status` para ver progresso\n",
    "- Use nomes de arquivo com timestamp para backups\n",
    "- Processe em blocos para datasets muito grandes (>1000 linhas)\n",
    "- Tenha uma estrat\u00e9gia de backup antes de come\u00e7ar\n",
    "- Teste com subset pequeno antes do dataset completo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover arquivos tempor\u00e1rios\n",
    "if os.path.exists(arquivo_parcial):\n",
    "    os.remove(arquivo_parcial)\n",
    "    print(f\"Removido: {arquivo_parcial}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Pr\u00f3ximos Passos\n",
    "\n",
    "- [08_rate_limiting.ipynb](08_rate_limiting.ipynb) - Configurar rate limiting\n",
    "- [05_advanced_legal.ipynb](05_advanced_legal.ipynb) - Exemplo avan\u00e7ado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
